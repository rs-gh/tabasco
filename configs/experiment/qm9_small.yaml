# @package _global_

tags: ["qm9", "small"]

datamodule:
  _target_: tabasco.data.lmdb_datamodule.LmdbDataModule

  data_dir: ./data/processed_qm9_train.pt
  val_data_dir: ./data/processed_qm9_val.pt
  test_data_dir: ./data/processed_qm9_test.pt
  lmdb_dir: ./data/lmdb_qm9

  add_random_rotation: true
  add_random_permutation: false
  reorder_to_smiles_order: true
  remove_hydrogens: true

  batch_size: 256
  num_workers: 4

model:
  net:
    _target_: tabasco.models.components.transformer_module.TransformerModule
    hidden_dim: 128
    num_layers: 16
    num_heads: 8
    activation: SiLU
    implementation: reimplemented
    cross_attention: true

callbacks:
  ema:
    _target_: tabasco.callbacks.ema.EMA
    decay: 0.999
    every_n_steps: 1

lightning_module:
  optimizer:
    lr: 0.002

trainer:
  max_epochs: 100

logger:
  wandb:
    name: "tabasco-qm9-small"
    project: "tabasco"
